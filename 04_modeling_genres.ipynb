{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aed2509-7d11-4ec7-a5dd-e4d4c5babcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ef770cb-0e70-4618-ac38-15b80c3385c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_df = pd.read_csv('./data/fiction_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff839f13-914d-4d9e-a80f-3d7cf5286a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to evaluate\n",
    "- Logistic Regression\n",
    "Random Forest\n",
    "Support Vector\n",
    "Neural Network\n",
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b107b-b718-4349-a19e-f4a63bb3f2b1",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4e9e072-eee6-4bf7-9762-b19cf847056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(pipeline, params, X_train, y_train):\n",
    "    gs = GridSearchCV(pipeline,\n",
    "                      param_grid = params,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    return f'Best Score: {gs.best_score_}, Params: {gs.best_params_}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5dc235e-5b3f-4597-98f8-a797ce233b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_gs(pipeline, params, X_train, y_train):\n",
    "    gs = GridSearchCV(pipeline,\n",
    "                      param_grid = params,\n",
    "                      n_jobs=-1)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "634f2337-f941-4017-8afa-c7375ed3c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(gs, X_train, y_train, X_test, y_test):\n",
    "    gs.fit(X_train, y_train)\n",
    "    return f'Train Score: {gs.score(X_train, y_train)}, Test Score: {gs.score(X_test, y_test)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0723855c-319b-4f3c-a004-97c8b3432add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(pipeline, X_train, X_test, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    prediction = pipeline.predict(X_test)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1ddf7ec-a9af-4f2e-bd38-ba094d8f8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_scores(model, y_test, y_pred):\n",
    "    dataframe = pd.DataFrame(columns = ['Recall', 'Precision', 'F1', 'Accuracy'])\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    dataframe.loc[model] = [recall, precision, f1, accuracy]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89090767-22d7-4bc3-8266-473dda4954d6",
   "metadata": {},
   "source": [
    "## Fiction Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6418b6-9b13-4395-b85e-cc2f87e800d8",
   "metadata": {},
   "source": [
    "### Baseline Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76e8afb5-7a7d-4484-9d24-49d91ed02106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pride and Prejudice                                                 0.02836\n",
       "Great Expectations                                                  0.00840\n",
       "Brave New World                                                     0.00740\n",
       "The Great Gatsby                                                    0.00678\n",
       "The Hobbitt, or there and back again; illustrated by the author.    0.00592\n",
       "                                                                     ...   \n",
       "Man's Fate                                                          0.00002\n",
       "That Summer                                                         0.00002\n",
       "Heller with a Gun                                                   0.00002\n",
       "The Stalkers (Plainsmen (Audio))                                    0.00002\n",
       "Star Trek 2005 Wall Calendar                                        0.00002\n",
       "Name: Title, Length: 9379, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiction_df['Title'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18ce2711-2cda-4429-9ddf-c1b7bafd5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fiction_df['description']\n",
    "y = fiction_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f32134b-fbaa-49d5-9e43-b10e999d83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "435649a2-cf14-4f4f-9ac5-a01e0e50106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_lemmatizer(text):\n",
    "    wnet = WordNetLemmatizer()\n",
    "    # exclude words with apostrophes and numbers\n",
    "    return [wnet.lemmatize(w) for w in text.split() if \"'\" not in w and not w.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "366be187-e46e-4126-8608-3dd0da9cc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet = WordNetLemmatizer()\n",
    "lem_stopwords = [wnet.lemmatize(w) for w in stopwords.words('english')]\n",
    "\n",
    "contractions = ['ve', 't', \"'s'\", 'd', 'll', 'm', 're']\n",
    "lem_contractions = [wnet.lemmatize(contraction) for contraction in contractions]\n",
    "\n",
    "numbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "lem_numbers = [wnet.lemmatize(num) for num in numbers]\n",
    "\n",
    "lem_stopwords = lem_stopwords + lem_contractions + lem_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aef9f2-6363-49c8-8e9a-990d549833aa",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17d74311-3201-4546-890f-e72fbbaf2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2ec06-ea73-4271-90aa-467e8189bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to evaluate\n",
    "Support Vector\n",
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1913c227-b2de-4c6b-9acf-aa398ff9e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words = lem_stopwords, \n",
    "                           tokenizer = my_lemmatizer,\n",
    "                           token_pattern = None,\n",
    "                           max_features = 5_000)),\n",
    "    ('mnb', MultinomialNB(alpha = 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1256cbbf-6de1-4651-a259-c315bc39b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_params = {\n",
    "    'tf__min_df': [0.1, 0.25, 0.5, 1.0],\n",
    "    'tf__max_df': [0.25, 0.5, 0.8, 1.0],\n",
    "    'tf__ngram_range': [(1,1), (2,2), (3,3)],\n",
    "    'mnb__alpha': [0.1, 0.25, 0.5, 1],\n",
    "    'mnb__fit_prior': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0392fbc4-f0ec-48d1-bfb7-e4557fe2b2ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1320 fits failed out of a total of 1920.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "840 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 2133, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1401, in fit_transform\n",
      "    X, self.stop_words_ = self._limit_features(\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1253, in _limit_features\n",
      "    raise ValueError(\n",
      "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "480 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 2133, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1398, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [4.20720000e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.47066667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.47066667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.47066667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.23866667e-01 1.08533333e-02 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.55600000e-01 1.08533333e-02 2.40000000e-04 8.37866667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.55600000e-01 1.08533333e-02 2.40000000e-04 8.37866667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.55600000e-01 1.08533333e-02 2.40000000e-04 8.37866667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.80346667e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.07253333e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.07253333e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.07253333e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.88880000e-01 1.05600000e-02 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.19893333e-01 1.05600000e-02 2.40000000e-04 8.02133333e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.19893333e-01 1.05600000e-02 2.40000000e-04 8.02133333e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.19893333e-01 1.05600000e-02 2.40000000e-04 8.02133333e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.42666667e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.61040000e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.61040000e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.61040000e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.52480000e-01 1.05066667e-02 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.79360000e-01 1.05066667e-02 2.40000000e-04 7.69066667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.79360000e-01 1.05066667e-02 2.40000000e-04 7.69066667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.79360000e-01 1.05066667e-02 2.40000000e-04 7.69066667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.05520000e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.21946667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.21946667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.21946667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.98106667e-01 9.81333333e-03 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.25440000e-01 9.81333333e-03 2.40000000e-04 7.19466667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.25440000e-01 9.81333333e-03 2.40000000e-04 7.19466667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.25440000e-01 9.81333333e-03 2.40000000e-04 7.19466667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Best Score: 0.6556000000000001, Params: {'mnb__alpha': 0.1, 'mnb__fit_prior': False, 'tf__max_df': 0.5, 'tf__min_df': 0.1, 'tf__ngram_range': (1, 1)}\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params(mnb_pipe, mnb_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b03bfd4-ca55-4f06-84c5-99f2db948f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_gs = return_gs(mnb_pipe, mnb_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17020be4-e9c4-4073-b5ab-3f4adcc81ec1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1320 fits failed out of a total of 1920.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "840 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 2133, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1401, in fit_transform\n",
      "    X, self.stop_words_ = self._limit_features(\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1253, in _limit_features\n",
      "    raise ValueError(\n",
      "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "480 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 2133, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1398, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [4.20720000e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.47066667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.47066667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.47066667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.23866667e-01 1.08533333e-02 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.55600000e-01 1.08533333e-02 2.40000000e-04 8.37866667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.55600000e-01 1.08533333e-02 2.40000000e-04 8.37866667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.55600000e-01 1.08533333e-02 2.40000000e-04 8.37866667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.80346667e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.07253333e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.07253333e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.07253333e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.88880000e-01 1.05600000e-02 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.19893333e-01 1.05600000e-02 2.40000000e-04 8.02133333e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.19893333e-01 1.05600000e-02 2.40000000e-04 8.02133333e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 6.19893333e-01 1.05600000e-02 2.40000000e-04 8.02133333e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.42666667e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.61040000e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.61040000e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.61040000e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.52480000e-01 1.05066667e-02 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.79360000e-01 1.05066667e-02 2.40000000e-04 7.69066667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.79360000e-01 1.05066667e-02 2.40000000e-04 7.69066667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.79360000e-01 1.05066667e-02 2.40000000e-04 7.69066667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.05520000e-01 2.86400000e-02 2.86400000e-02            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.21946667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.21946667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 3.21946667e-01 2.86400000e-02 2.86400000e-02 2.86400000e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 4.98106667e-01 9.81333333e-03 2.40000000e-04            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.25440000e-01 9.81333333e-03 2.40000000e-04 7.19466667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.25440000e-01 9.81333333e-03 2.40000000e-04 7.19466667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 5.25440000e-01 9.81333333e-03 2.40000000e-04 7.19466667e-02\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Train Score: 0.7156, Test Score: 0.6444'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(mnb_gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0d58538-943b-4a9c-96ea-96d172c5a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pred = predictions(mnb_pipe, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8794fa8f-1ac4-4b17-abc1-2a6823c7e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.63488</td>\n",
       "      <td>0.490088</td>\n",
       "      <td>0.535894</td>\n",
       "      <td>0.63488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Recall  Precision        F1  Accuracy\n",
       "Multinomial Naive Bayes  0.63488   0.490088  0.535894   0.63488"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_scores('Multinomial Naive Bayes', y_test, mnb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939be4e-d9d9-4a56-81eb-128d69599586",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fiction_pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32edc60-8446-42f7-8fdd-8c9e9bf4ed13",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71a1bd39-f29a-4854-9c73-d1d7c40fc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words = lem_stopwords, \n",
    "                           tokenizer = my_lemmatizer,\n",
    "                           token_pattern = None,\n",
    "                           max_features = 5_000)),\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8c223dc-c80b-43e3-a8ab-e03048b0e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {\n",
    "    'tf__min_df': [0.1, 0.25, 0.5, 1.0],\n",
    "    'tf__max_df': [0.25, 0.5, 0.8, 1.0],\n",
    "    'tf__ngram_range': [(1,1), (2,2), (3,3)],\n",
    "    'rfc__n_estimators': [100, 200, 300],\n",
    "    'rfc__max_depth': [5, 10, 20],\n",
    "    'rfc__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e8795-5649-4715-93cf-ea2aa6be2539",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_params(rfc_pipe, rfc_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc86b2-04ca-474e-9b6d-8b5310ad608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs = return_gs(rfc_pipe, rfc_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00ec3b-b444-433f-b87e-96304d8e1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores(rfc_gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33ce63-b422-4b16-8832-7cc56744f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = predictions(rfc_pipe, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec744f4-965d-4064-aa89-30e376eedc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_scores('Random Forest Classifier', y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a196ec-d3de-40fb-b6ec-5687d0b4d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b21644bb-3641-4abd-8669-288af4ae446f",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e68ca8-1391-4233-bbdc-073f45bb3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words = lem_stopwords, \n",
    "                           tokenizer = my_lemmatizer,\n",
    "                           token_pattern = None,\n",
    "                           max_features = 5_000)),\n",
    "    ('rfc', RandomForestClassifier(max_features = 5_000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66f019-4402-43a1-836b-bb5fdad717b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'tf__min_df': [0.1, 0.25, 0.5, 1.0],\n",
    "    'tf__max_df': [0.25, 0.5, 0.8, 1.0],\n",
    "    'tf__ngram_range': [(1,1), (2,2), (3,3)],\n",
    "    'rfc__n_estimators': [100, 200, 300],\n",
    "    'rfr__max_depth': [5, 10, 20],\n",
    "    'rfc__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d4ab3f-825a-4c2a-afa1-949245a01179",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params(lr_pipe, lr_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cafb2-3008-451d-b60c-433229bff4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs = return_gs(lr_pipe, lr_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6992d34-db6f-431b-b05e-bde84b14347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores(lr_gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575c413-a711-4eff-9d48-6d633e44e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = predictions(lr_pipe, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8ce93-f91d-423d-83b0-fa86acc41cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_scores('Logistic Regression', y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c32265-cfa3-4151-aa7f-a77b2f4479da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64892872-f9a2-432e-98e2-6111a99130d7",
   "metadata": {},
   "source": [
    "### Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab7aa5-3881-41bc-bfbd-2eabd773566b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60c2f8-00ae-49cb-95f0-d181ba9c565f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74810f46-2d14-4791-a0db-4da49e4587b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da9f8b-0d5e-4b3b-a43d-21b475250bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c6cf0-7028-4f26-8cbb-7e374c7fe59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18e50a-c9b8-4f28-9be2-0a41c7fbd1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
