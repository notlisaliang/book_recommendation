{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef61def-aa89-43d4-932b-dcfd4b1c51d7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f26990-6361-4ee4-9cb5-d2b4cab76704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32809e1-dbf7-40b8-a0b5-4ec1ce33686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afea11b-ba07-45c3-8d1a-4167ff6624e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787051c-9015-44e3-8e7c-94eb2199a9e3",
   "metadata": {},
   "source": [
    "### Importing Data\n",
    "\n",
    "This notebook is an extension of part 4 of this project. I read in all my datasets and wanted explore how well the models performed on them. Like before, the only model that ran was a Multinomial Naive Bayes, but a few datasets were able to run a Random Forest Classifier. I wanted to build a Streamlit App and will select the models that have the highest accuracy (and hopefully precision) scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488274d7-91dd-4798-a4e5-ebefe7b8d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_df = pd.read_csv('./data/fiction_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46b283b-ccbc-4b4f-a987-acc6bf4e9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvf_df = pd.read_csv('./data/jvf_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904c9077-09cc-42e8-b93e-ec00162ca7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_df = pd.read_csv('./data/bio_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba7051c-f73d-4339-9524-9757d94cc81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = pd.read_csv('./data/overall_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3a03a1-7080-4e14-9754-af42fe1ab1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('./data/review_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5716b-814c-49c7-9392-789b1f87a8e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f5f38-db1d-436b-a540-3ad031baf514",
   "metadata": {},
   "source": [
    "* **best_params(pipeline, params, X_train, y_train)**: Reads in a pipeline, parameters, X_train, and y_train set that you've created, performs a GridSearchCV to find the best score and parameters through hypertuning. \n",
    "* **return_gs(pipeline, params, X_train, y_train)**: Returns GridSearch of a given pipeline and parameters\n",
    "* **scores(gs, X_train, y_train, X_test, y_test)**: Using the returned gridsearch, the function will fit the model and perform a train-test-split to evaluate the R2 Train and Test scores.\n",
    "* **predictions(pipeline, X_train, X_test, y_train)**: Returns predictions based on a pipeline and its model\n",
    "* **classification_scores(model, y_test, y_pred)**: Using the predictions, it'll return recall, precision, f1, and accuracy scores for you to evaluate.\n",
    "\n",
    "Note: Functions are reused from [my previous Subreddit project](https://git.generalassemb.ly/lisaliang/project-3.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b06224c-5554-488e-9033-9f5a6b5d92b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(pipeline, params, X_train, y_train):\n",
    "    gs = GridSearchCV(pipeline,\n",
    "                      param_grid = params,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    return f'Best Score: {gs.best_score_}, Params: {gs.best_params_}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc8dc409-df5a-4627-8cd9-0b6c363b33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_gs(pipeline, params, X_train, y_train):\n",
    "    gs = GridSearchCV(pipeline,\n",
    "                      param_grid = params,\n",
    "                      n_jobs=-1)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c63e096-8cb4-4761-a080-601cbfc1c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(gs, X_train, y_train, X_test, y_test):\n",
    "    gs.fit(X_train, y_train)\n",
    "    return f'Train Score: {gs.score(X_train, y_train)}, Test Score: {gs.score(X_test, y_test)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "363bbda7-e6f6-4d01-9b74-53434d9f819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(pipeline, X_train, X_test, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    prediction = pipeline.predict(X_test)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb05a8b-0f98-4c11-a80a-fcc5483b2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_scores(model, y_test, y_pred):\n",
    "    dataframe = pd.DataFrame(columns = ['Recall', 'Precision', 'F1', 'Accuracy'])\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    dataframe.loc[model] = [recall, precision, f1, accuracy]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedb216-ffe4-4964-bc17-df7870920242",
   "metadata": {},
   "source": [
    "* **my_lemmatizer(text)**: This function lemmatizes inputted text to their dictionary forms. It adds conditions to filter out words with apostrophes or digits so they are done as accurately as possible.\n",
    "\n",
    "Additional: We created a list of English stopwords, contractions, and numbers for the model to remove while it's iterating through the text. These attributes were seen as not adding significance in helping the model distinguish book titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "106a4378-0a80-4343-a093-787df2345b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_lemmatizer(text):\n",
    "    wnet = WordNetLemmatizer()\n",
    "    # exclude words with apostrophes and numbers\n",
    "    return [wnet.lemmatize(w) for w in text.split() if \"'\" not in w and not w.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f79e76af-1cb2-47b8-a2a3-699adbee9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet = WordNetLemmatizer()\n",
    "lem_stopwords = [wnet.lemmatize(w) for w in stopwords.words('english')]\n",
    "\n",
    "contractions = ['ve', 't', \"'s'\", 'd', 'll', 'm', 're']\n",
    "lem_contractions = [wnet.lemmatize(contraction) for contraction in contractions]\n",
    "\n",
    "numbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "lem_numbers = [wnet.lemmatize(num) for num in numbers]\n",
    "\n",
    "lem_stopwords = lem_stopwords + lem_contractions + lem_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ae731f-afa9-42c9-9a1c-8a1e2ab67911",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fiction (MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d16701b7-42b3-4107-84aa-d29c8e546943",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fiction = fiction_df['description']\n",
    "y_fiction = fiction_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cf1f9c1-4c6f-483b-97f7-85cf30cd039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fiction, y_fiction, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91183f2c-d2aa-4b99-8064-1f2bd2ed9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words = lem_stopwords, \n",
    "                           tokenizer = my_lemmatizer,\n",
    "                           token_pattern = None,\n",
    "                           max_features = 500)),\n",
    "    ('mnb', MultinomialNB(alpha = 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64c614c2-2e4d-4f31-8c73-c41670c2eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_params = {\n",
    "    'tf__min_df': [0.05, 0.1],\n",
    "    'tf__max_df': [0.5],\n",
    "    'tf__ngram_range': [(1,1)],\n",
    "    'mnb__alpha': [0.05, 0.1],\n",
    "    'mnb__fit_prior': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d8dd639-f1fa-4dc4-8619-8d68907277a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_gs = return_gs(fiction_pipe, fiction_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace7d556-64b7-4e58-971e-80345eb395fa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Train Score: 0.8729866666666667, Test Score: 0.81104'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(fiction_gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f73c15c-a80b-466a-b5e3-a5f6c03db8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_pred = predictions(fiction_pipe, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c249eff-9f29-4a82-93fa-cd120eccd5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fiction</th>\n",
       "      <td>0.67144</td>\n",
       "      <td>0.515462</td>\n",
       "      <td>0.57021</td>\n",
       "      <td>0.67144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Recall  Precision       F1  Accuracy\n",
       "Fiction  0.67144   0.515462  0.57021   0.67144"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_scores('Fiction', y_test, fiction_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8ed5392-1a66-49b3-b7ce-4478e599127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fiction_pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(fiction_pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38f056-1dc0-4f42-ba85-aab18d2d3448",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Juvenile Fiction (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf6e0967-a69e-4ea7-a923-dbba337a0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_jvf = jvf_df['description']\n",
    "y_jvf = jvf_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6058bf8-6344-4bbf-9f3d-95571b1ae016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_jvf, y_jvf, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eab1433d-8d83-40e9-9cc3-cebd84252a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvf_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words = lem_stopwords, \n",
    "                           tokenizer = my_lemmatizer,\n",
    "                           token_pattern = None,\n",
    "                           max_features = 1_000)),\n",
    "    ('rfc', RandomForestClassifier(max_features = 1_000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2695f23e-648f-4afc-bf78-e94cf281ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvf_params = {\n",
    "    'tf__min_df': [0.05, 0.1],\n",
    "    'tf__max_df': [0.5],\n",
    "    'tf__ngram_range': [(1,1)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4937a58-28c7-49f5-a6a3-f85bcd57fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvf_gs = return_gs(jvf_pipe, jvf_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98fffc37-53cf-4de6-b42a-8b1b8901469d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Train Score: 0.7850666666666667, Test Score: 0.75784'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(jvf_gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89f5d382-47c5-4e25-9024-feb4c33c9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvf_pred = predictions(jvf_pipe, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b3bb783-9aa3-4585-ac60-42650496c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Juvenile Fiction</th>\n",
       "      <td>0.84768</td>\n",
       "      <td>0.774386</td>\n",
       "      <td>0.801599</td>\n",
       "      <td>0.84768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Recall  Precision        F1  Accuracy\n",
       "Juvenile Fiction  0.84768   0.774386  0.801599   0.84768"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_scores('Juvenile Fiction', y_test, jvf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec048f9c-e0ca-4cd4-94f7-5a96abe915b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jvf_pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(jvf_pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754becb9-229c-4179-91f6-bc5f63f9faba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Biography & Autobiography (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e44aa959-b49c-4d4c-8659-3c5f57b6a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bio = bio_df['description']\n",
    "y_bio = bio_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03b98866-0fc8-4c63-b24b-348710b0f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bio, y_bio, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160acb01-3c69-4374-a62e-ad165769b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words = lem_stopwords, \n",
    "                           tokenizer = my_lemmatizer,\n",
    "                           token_pattern = None,\n",
    "                           max_features = 1_000)),\n",
    "    ('rfc', RandomForestClassifier(max_features = 1_000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43f8e59b-4ae7-4cf4-bd50-06f83213211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_params = {\n",
    "    'tf__min_df': [0.05, 0.1],\n",
    "    'tf__max_df': [0.5],\n",
    "    'tf__ngram_range': [(1,1)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be27c2cd-c391-4a5a-94fd-7e66035c857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_gs = return_gs(bio_pipe, bio_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f35bb7d7-9a11-4922-b591-71393e1cded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Train Score: 0.90608, Test Score: 0.89288'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(bio_gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0630ca8d-1eea-4be8-88e9-8acd393ab07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_pred = predictions(bio_pipe, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72c95d40-9585-4b54-9f46-d9e79646a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lisaliang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biography &amp; Autobiography</th>\n",
       "      <td>0.91488</td>\n",
       "      <td>0.875228</td>\n",
       "      <td>0.888892</td>\n",
       "      <td>0.91488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Recall  Precision        F1  Accuracy\n",
       "Biography & Autobiography  0.91488   0.875228  0.888892   0.91488"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_scores('Biography & Autobiography', y_test, bio_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08d0d109-b3c5-437c-a3a0-6e4350694032",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bio_rfc.pkl', 'wb') as f:\n",
    "    pickle.dump(bio_pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4ddb5-4277-464f-bced-949a36f7a126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
